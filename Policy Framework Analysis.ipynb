{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DNT3I2xkY9vA"
   },
   "source": [
    "# **Policy Framework Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "cQVMUaBuZg6G"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Policy Framework Analysis\n",
    "Maps policies to responsible AI frameworks and generates comparative analysis\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "from typing import List, Dict, Tuple\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "class PolicyFrameworkMapper:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the policy framework mapper\"\"\"\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "        # Core responsible AI principles with associated keywords\n",
    "        self.ai_principles = {\n",
    "            'fairness': {\n",
    "                'keywords': ['fairness', 'bias', 'discrimination', 'equity', 'equal', 'impartial',\n",
    "                           'équité', 'biais', 'discrimination', 'égal',  # French\n",
    "                           'عدالة', 'تحيز', 'تمييز', 'منصف'],  # Arabic\n",
    "                'weight': 1.0\n",
    "            },\n",
    "            'transparency': {\n",
    "                'keywords': ['transparency', 'explainable', 'interpretable', 'understandable',\n",
    "                           'clear', 'open', 'transparent', 'explicable', 'interprétable',  # French\n",
    "                           'شفافية', 'واضح', 'مفهوم'],  # Arabic\n",
    "                'weight': 1.0\n",
    "            },\n",
    "            'accountability': {\n",
    "                'keywords': ['accountability', 'responsible', 'liability', 'oversight',\n",
    "                           'governance', 'responsabilité', 'gouvernance',  # French\n",
    "                           'مساءلة', 'مسؤولية', 'حوكمة'],  # Arabic\n",
    "                'weight': 1.0\n",
    "            },\n",
    "            'privacy': {\n",
    "                'keywords': ['privacy', 'data protection', 'confidentiality', 'personal data',\n",
    "                           'vie privée', 'protection des données', 'confidentialité',  # French\n",
    "                           'خصوصية', 'حماية البيانات', 'سرية'],  # Arabic\n",
    "                'weight': 1.0\n",
    "            },\n",
    "            'human_oversight': {\n",
    "                'keywords': ['human oversight', 'human control', 'human intervention',\n",
    "                           'human-in-the-loop', 'supervision', 'contrôle humain',  # French\n",
    "                           'إشراف بشري', 'تحكم بشري', 'تدخل بشري'],  # Arabic\n",
    "                'weight': 1.0\n",
    "            },\n",
    "            'robustness': {\n",
    "                'keywords': ['robustness', 'reliability', 'safety', 'security', 'resilience',\n",
    "                           'robustesse', 'fiabilité', 'sécurité',  # French\n",
    "                           'قوة', 'موثوقية', 'أمان', 'أمن'],  # Arabic\n",
    "                'weight': 1.0\n",
    "            },\n",
    "            'non_maleficence': {\n",
    "                'keywords': ['harm', 'risk', 'safety', 'protection', 'prevent', 'avoid',\n",
    "                           'dommage', 'risque', 'prévenir', 'éviter',  # French\n",
    "                           'ضرر', 'خطر', 'حماية', 'منع', 'تجنب'],  # Arabic\n",
    "                'weight': 1.0\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Policy document classification patterns\n",
    "        self.policy_types = {\n",
    "            'law': ['act', 'law', 'regulation', 'statute', 'legal framework'],\n",
    "            'strategy': ['strategy', 'plan', 'roadmap', 'framework', 'initiative'],\n",
    "            'guideline': ['guideline', 'guidance', 'recommendation', 'best practice'],\n",
    "            'report': ['report', 'study', 'analysis', 'assessment', 'evaluation']\n",
    "        }\n",
    "\n",
    "    def analyze_policy_document(self, document: Dict) -> Dict:\n",
    "        \"\"\"Analyze a single policy document for AI principles coverage\"\"\"\n",
    "        content = document.get('content_preview', '') + ' ' + document.get('title', '')\n",
    "\n",
    "        # Calculate principle scores\n",
    "        principle_scores = {}\n",
    "        for principle, config in self.ai_principles.items():\n",
    "            score = self._calculate_principle_score(content, config['keywords'])\n",
    "            principle_scores[principle] = score\n",
    "\n",
    "        # Extract additional metadata\n",
    "        analysis = {\n",
    "            'document_id': document.get('url', 'unknown'),\n",
    "            'title': document.get('title', 'Unknown'),\n",
    "            'country': document.get('country', 'unknown'),\n",
    "            'document_type': document.get('document_type', 'unknown'),\n",
    "            'principle_scores': principle_scores,\n",
    "            'overall_coverage': np.mean(list(principle_scores.values())),\n",
    "            'top_principles': self._get_top_principles(principle_scores, top_n=3),\n",
    "            'coverage_gaps': self._identify_gaps(principle_scores),\n",
    "            'analysis_date': datetime.now().isoformat()\n",
    "        }\n",
    "\n",
    "        return analysis\n",
    "\n",
    "    def _calculate_principle_score(self, text: str, keywords: List[str]) -> float:\n",
    "        \"\"\"Calculate how well a text covers a specific AI principle\"\"\"\n",
    "        if not text:\n",
    "            return 0.0\n",
    "\n",
    "        text_lower = text.lower()\n",
    "        total_words = len(text.split())\n",
    "\n",
    "        if total_words == 0:\n",
    "            return 0.0\n",
    "\n",
    "        # Count keyword occurrences\n",
    "        keyword_count = sum(text_lower.count(keyword.lower()) for keyword in keywords)\n",
    "\n",
    "        # Calculate normalized score\n",
    "        score = min(keyword_count / total_words * 100, 1.0)  # Cap at 1.0\n",
    "\n",
    "        return round(score, 3)\n",
    "\n",
    "    def _get_top_principles(self, principle_scores: Dict, top_n: int = 3) -> List[Tuple[str, float]]:\n",
    "        \"\"\"Get top N principles by score\"\"\"\n",
    "        sorted_principles = sorted(principle_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        return sorted_principles[:top_n]\n",
    "\n",
    "    def _identify_gaps(self, principle_scores: Dict, threshold: float = 0.1) -> List[str]:\n",
    "        \"\"\"Identify principles with low coverage (potential gaps)\"\"\"\n",
    "        gaps = [principle for principle, score in principle_scores.items() if score < threshold]\n",
    "        return gaps\n",
    "\n",
    "    def analyze_document_collection(self, documents: List[Dict]) -> Dict:\n",
    "        \"\"\"Analyze a collection of policy documents\"\"\"\n",
    "        analyses = []\n",
    "\n",
    "        for doc in documents:\n",
    "            analysis = self.analyze_policy_document(doc)\n",
    "            analyses.append(analysis)\n",
    "\n",
    "        # Generate collection-level insights\n",
    "        collection_analysis = {\n",
    "            'total_documents': len(documents),\n",
    "            'documents': analyses,\n",
    "            'country_coverage': self._analyze_country_coverage(analyses),\n",
    "            'principle_coverage_summary': self._summarize_principle_coverage(analyses),\n",
    "            'document_type_distribution': self._analyze_document_types(analyses),\n",
    "            'gap_analysis': self._perform_gap_analysis(analyses),\n",
    "            'recommendations': self._generate_recommendations(analyses)\n",
    "        }\n",
    "\n",
    "        return collection_analysis\n",
    "\n",
    "    def _analyze_country_coverage(self, analyses: List[Dict]) -> Dict:\n",
    "        \"\"\"Analyze principle coverage by country\"\"\"\n",
    "        country_coverage = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "        for analysis in analyses:\n",
    "            country = analysis['country']\n",
    "            for principle, score in analysis['principle_scores'].items():\n",
    "                country_coverage[country][principle].append(score)\n",
    "\n",
    "        # Calculate averages\n",
    "        country_averages = {}\n",
    "        for country, principles in country_coverage.items():\n",
    "            country_averages[country] = {\n",
    "                principle: np.mean(scores) for principle, scores in principles.items()\n",
    "            }\n",
    "\n",
    "        return country_averages\n",
    "\n",
    "    def _summarize_principle_coverage(self, analyses: List[Dict]) -> Dict:\n",
    "        \"\"\"Summarize overall principle coverage across all documents\"\"\"\n",
    "        principle_scores = defaultdict(list)\n",
    "\n",
    "        for analysis in analyses:\n",
    "            for principle, score in analysis['principle_scores'].items():\n",
    "                principle_scores[principle].append(score)\n",
    "\n",
    "        summary = {}\n",
    "        for principle, scores in principle_scores.items():\n",
    "            summary[principle] = {\n",
    "                'mean': np.mean(scores),\n",
    "                'std': np.std(scores),\n",
    "                'min': np.min(scores),\n",
    "                'max': np.max(scores),\n",
    "                'documents_with_coverage': sum(1 for score in scores if score > 0.1)\n",
    "            }\n",
    "\n",
    "        return summary\n",
    "\n",
    "    def _analyze_document_types(self, analyses: List[Dict]) -> Dict:\n",
    "        \"\"\"Analyze distribution of document types\"\"\"\n",
    "        type_counts = defaultdict(int)\n",
    "        type_scores = defaultdict(list)\n",
    "\n",
    "        for analysis in analyses:\n",
    "            doc_type = analysis['document_type']\n",
    "            type_counts[doc_type] += 1\n",
    "            type_scores[doc_type].append(analysis['overall_coverage'])\n",
    "\n",
    "        type_analysis = {}\n",
    "        for doc_type, count in type_counts.items():\n",
    "            type_analysis[doc_type] = {\n",
    "                'count': count,\n",
    "                'average_coverage': np.mean(type_scores[doc_type]) if type_scores[doc_type] else 0,\n",
    "                'percentage': (count / len(analyses)) * 100\n",
    "            }\n",
    "\n",
    "        return type_analysis\n",
    "\n",
    "    def _perform_gap_analysis(self, analyses: List[Dict]) -> Dict:\n",
    "        \"\"\"Identify gaps in AI principle coverage\"\"\"\n",
    "        all_gaps = defaultdict(int)\n",
    "        country_gaps = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "        for analysis in analyses:\n",
    "            country = analysis['country']\n",
    "            for gap in analysis['coverage_gaps']:\n",
    "                all_gaps[gap] += 1\n",
    "                country_gaps[country][gap] += 1\n",
    "\n",
    "        gap_analysis = {\n",
    "            'most_common_gaps': dict(sorted(all_gaps.items(), key=lambda x: x[1], reverse=True)),\n",
    "            'gaps_by_country': dict(country_gaps),\n",
    "            'total_documents_with_gaps': sum(1 for analysis in analyses if analysis['coverage_gaps'])\n",
    "        }\n",
    "\n",
    "        return gap_analysis\n",
    "\n",
    "    def _generate_recommendations(self, analyses: List[Dict]) -> List[str]:\n",
    "        \"\"\"Generate recommendations based on analysis\"\"\"\n",
    "        recommendations = []\n",
    "\n",
    "        # Analyze principle coverage\n",
    "        principle_scores = defaultdict(list)\n",
    "        for analysis in analyses:\n",
    "            for principle, score in analysis['principle_scores'].items():\n",
    "                principle_scores[principle].append(score)\n",
    "\n",
    "        # Identify weak areas\n",
    "        weak_principles = []\n",
    "        for principle, scores in principle_scores.items():\n",
    "            if np.mean(scores) < 0.3:  # Threshold for weak coverage\n",
    "                weak_principles.append(principle)\n",
    "\n",
    "        if weak_principles:\n",
    "            recommendations.append(f\"Strengthen coverage of: {', '.join(weak_principles)}\")\n",
    "\n",
    "        # Country-specific recommendations\n",
    "        country_coverage = self._analyze_country_coverage(analyses)\n",
    "        for country, principles in country_coverage.items():\n",
    "            weak_country_principles = [p for p, score in principles.items() if score < 0.2]\n",
    "            if weak_country_principles:\n",
    "                recommendations.append(f\"{country}: Focus on {', '.join(weak_country_principles)}\")\n",
    "\n",
    "        # Document type recommendations\n",
    "        type_analysis = self._analyze_document_types(analyses)\n",
    "        low_coverage_types = [t for t, data in type_analysis.items() if data['average_coverage'] < 0.3]\n",
    "        if low_coverage_types:\n",
    "            recommendations.append(f\"Improve AI principle integration in: {', '.join(low_coverage_types)}\")\n",
    "\n",
    "        return recommendations\n",
    "\n",
    "    def generate_coverage_matrix(self, analyses: List[Dict]) -> pd.DataFrame:\n",
    "        \"\"\"Generate a coverage matrix showing principles vs countries/documents\"\"\"\n",
    "        countries = list(set(analysis['country'] for analysis in analyses))\n",
    "        principles = list(self.ai_principles.keys())\n",
    "\n",
    "        # Create matrix\n",
    "        matrix_data = []\n",
    "        for country in countries:\n",
    "            country_docs = [a for a in analyses if a['country'] == country]\n",
    "            country_row = {'country': country}\n",
    "\n",
    "            for principle in principles:\n",
    "                scores = [doc['principle_scores'][principle] for doc in country_docs]\n",
    "                country_row[principle] = np.mean(scores) if scores else 0\n",
    "\n",
    "            matrix_data.append(country_row)\n",
    "\n",
    "        df = pd.DataFrame(matrix_data)\n",
    "        return df.set_index('country')\n",
    "\n",
    "    def visualize_coverage_matrix(self, coverage_matrix: pd.DataFrame, save_path: str = None):\n",
    "        \"\"\"Create a heatmap visualization of the coverage matrix\"\"\"\n",
    "        plt.figure(figsize=(12, 8))\n",
    "\n",
    "        # Create heatmap\n",
    "        sns.heatmap(coverage_matrix,\n",
    "                   annot=True,\n",
    "                   cmap='RdYlGn',\n",
    "                   vmin=0,\n",
    "                   vmax=1,\n",
    "                   fmt='.3f',\n",
    "                   cbar_kws={'label': 'Coverage Score'})\n",
    "\n",
    "        plt.title('AI Principle Coverage by Country')\n",
    "        plt.xlabel('AI Principles')\n",
    "        plt.ylabel('Countries')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def export_analysis(self, analysis: Dict, output_path: str):\n",
    "        \"\"\"Export analysis results to JSON file\"\"\"\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(analysis, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "        self.logger.info(f\"Analysis exported to {output_path}\")\n",
    "\n",
    "    def generate_summary_report(self, analysis: Dict) -> str:\n",
    "        \"\"\"Generate a human-readable summary report\"\"\"\n",
    "        report = []\n",
    "        report.append(\"AI POLICY FRAMEWORK ANALYSIS REPORT\")\n",
    "        report.append(\"=\" * 50)\n",
    "        report.append(f\"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        report.append(f\"Total Documents Analyzed: {analysis['total_documents']}\")\n",
    "        report.append(\"\")\n",
    "\n",
    "        # Country coverage summary\n",
    "        report.append(\"COUNTRY COVERAGE SUMMARY\")\n",
    "        report.append(\"-\" * 30)\n",
    "        for country, principles in analysis['country_coverage'].items():\n",
    "            avg_coverage = np.mean(list(principles.values()))\n",
    "            report.append(f\"{country.upper()}: {avg_coverage:.3f} average coverage\")\n",
    "        report.append(\"\")\n",
    "\n",
    "        # Top principles globally\n",
    "        report.append(\"GLOBAL PRINCIPLE COVERAGE\")\n",
    "        report.append(\"-\" * 30)\n",
    "        principle_summary = analysis['principle_coverage_summary']\n",
    "        for principle, stats in sorted(principle_summary.items(),\n",
    "                                     key=lambda x: x[1]['mean'], reverse=True):\n",
    "            report.append(f\"{principle.replace('_', ' ').title()}: {stats['mean']:.3f} \"\n",
    "                         f\"(in {stats['documents_with_coverage']} documents)\")\n",
    "        report.append(\"\")\n",
    "\n",
    "        # Gap analysis\n",
    "        report.append(\"GAP ANALYSIS\")\n",
    "        report.append(\"-\" * 15)\n",
    "        gaps = analysis['gap_analysis']['most_common_gaps']\n",
    "        if gaps:\n",
    "            report.append(\"Most common gaps:\")\n",
    "            for gap, count in gaps.items():\n",
    "                report.append(f\"- {gap.replace('_', ' ').title()}: {count} documents\")\n",
    "        else:\n",
    "            report.append(\"No significant gaps identified.\")\n",
    "        report.append(\"\")\n",
    "\n",
    "        # Recommendations\n",
    "        report.append(\"RECOMMENDATIONS\")\n",
    "        report.append(\"-\" * 15)\n",
    "        for i, rec in enumerate(analysis['recommendations'], 1):\n",
    "            report.append(f\"{i}. {rec}\")\n",
    "\n",
    "        return \"\\n\".join(report)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
